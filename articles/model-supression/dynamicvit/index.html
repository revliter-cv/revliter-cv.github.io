<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<link rel=icon href=/favicon.ico>
<title>
DynamicViT:Efficient Vision Transformers with Dynamic Token Sparsification - Computer Vision Paper Reading
</title>
<meta name=description content="First update: 2022.10.19
 I just write the blog the same time I read it. So I will make it casual and may rewrite some content later.
The authors proposed in the abstract: we observe the final prediction in vision transformers is only based on a subset of most informative tokens, which is sufficient for accurate image recognition.
 HOW can we come to this conclusion?  Visualization:
About this visualization method: Paper related: Tranformer interpretability beyond attention visualization"><meta name=generator content="Hugo 0.92.2">
<link rel=stylesheet href=https://revliter-cv.github.io/css/main.css>
<meta property="og:title" content="DynamicViT:Efficient Vision Transformers with Dynamic Token Sparsification">
<meta property="og:description" content="First update: 2022.10.19
 I just write the blog the same time I read it. So I will make it casual and may rewrite some content later.
The authors proposed in the abstract: we observe the final prediction in vision transformers is only based on a subset of most informative tokens, which is sufficient for accurate image recognition.
 HOW can we come to this conclusion?  Visualization:
About this visualization method: Paper related: Tranformer interpretability beyond attention visualization">
<meta property="og:type" content="article">
<meta property="og:url" content="https://revliter-cv.github.io/articles/model-supression/dynamicvit/"><meta property="og:image" content="https://revliter-cv.github.io/digital-garden-logo.png"><meta property="article:section" content="articles">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://revliter-cv.github.io/digital-garden-logo.png">
<meta name=twitter:title content="DynamicViT:Efficient Vision Transformers with Dynamic Token Sparsification">
<meta name=twitter:description content="First update: 2022.10.19
 I just write the blog the same time I read it. So I will make it casual and may rewrite some content later.
The authors proposed in the abstract: we observe the final prediction in vision transformers is only based on a subset of most informative tokens, which is sufficient for accurate image recognition.
 HOW can we come to this conclusion?  Visualization:
About this visualization method: Paper related: Tranformer interpretability beyond attention visualization">
<meta itemprop=name content="DynamicViT:Efficient Vision Transformers with Dynamic Token Sparsification">
<meta itemprop=description content="First update: 2022.10.19
 I just write the blog the same time I read it. So I will make it casual and may rewrite some content later.
The authors proposed in the abstract: we observe the final prediction in vision transformers is only based on a subset of most informative tokens, which is sufficient for accurate image recognition.
 HOW can we come to this conclusion?  Visualization:
About this visualization method: Paper related: Tranformer interpretability beyond attention visualization">
<meta itemprop=wordCount content="535"><meta itemprop=image content="https://revliter-cv.github.io/digital-garden-logo.png">
<meta itemprop=keywords content>
<meta itemprop=name content="DynamicViT:Efficient Vision Transformers with Dynamic Token Sparsification">
<meta itemprop=description content="First update: 2022.10.19
 I just write the blog the same time I read it. So I will make it casual and may rewrite some content later.
The authors proposed in the abstract: we observe the final prediction in vision transformers is only based on a subset of most informative tokens, which is sufficient for accurate image recognition.
 HOW can we come to this conclusion?  Visualization:
About this visualization method: Paper related: Tranformer interpretability beyond attention visualization">
<meta itemprop=wordCount content="535"><meta itemprop=image content="https://revliter-cv.github.io/digital-garden-logo.png">
<meta itemprop=keywords content>
</head><body class="flex relative h-full min-h-screen"><aside class="will-change-transform transform transition-transform -translate-x-full absolute top-0 left-0 md:relative md:translate-x-0 w-3/4 md:w-60 h-full min-h-screen p-3 bg-slate-50 dark:bg-slate-800 border-r border-slate-200 dark:border-slate-700 flex flex-col gap-2.5 z-20 sidebar">
<p class="font-bold mb-5 flex items-center gap-2">
<button aria-label="Close sidebar" class="md:hidden menu-trigger-close p-1 rounded text-slate-800 dark:text-slate-50 hover:bg-slate-200 dark:hover:bg-slate-700"><svg class="h-6 w-6" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="18" y1="6" x2="6" y2="18"/><line x1="6" y1="6" x2="18" y2="18"/></svg></button>
<a href=https://revliter-cv.github.io/ class=px-2>
<span>Computer Vision Paper Reading</span>
</a>
<button aria-label="Toggle dark mode" class="dark-mode-toggle p-2 rounded border dark:border-slate-700 hover:bg-slate-200 dark:hover:bg-slate-700"><svg class="h-4 w-4" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="4"/><path d="M3 12h1m8-9v1m8 8h1m-9 8v1M5.6 5.6l.7.7m12.1-.7-.7.7m0 11.4.7.7M6.3 17.7l-.7.7"/></svg></button>
</p>
<ul class="list-none flex flex-col gap-1">
<li>
<a class="px-2 py-1.5 rounded-md text-sm flex items-center justify-between hover:bg-slate-200 dark:hover:bg-slate-700" href=/>
<span>Home</span>
</a>
</li>
<li>
<a class="px-2 py-1.5 rounded-md text-sm flex items-center justify-between text-slate-400 font-semibold pb-0 pl-1 border-b cursor-default pointer-events-none" href=#>
<span>Content</span>
</a>
</li>
<li>
<a class="px-2 py-1.5 rounded-md text-sm flex items-center justify-between hover:bg-slate-200 dark:hover:bg-slate-700" href=/articles>
<span>Articles</span>
</a>
</li>
<li>
<a class="px-2 py-1.5 rounded-md text-sm flex items-center justify-between hover:bg-slate-200 dark:hover:bg-slate-700" href=/works>
<span>Works done</span>
</a>
</li>
<li>
<a class="px-2 py-1.5 rounded-md text-sm flex items-center justify-between hover:bg-slate-200 dark:hover:bg-slate-700" href=/framework>
<span>Frameworks</span>
</a>
</li>
<li>
<a class="px-2 py-1.5 rounded-md text-sm flex items-center justify-between text-slate-400 font-semibold pb-0 pl-1 border-b cursor-default pointer-events-none" href=#>
<span>Links</span>
</a>
</li>
<li>
<a class="px-2 py-1.5 rounded-md text-sm flex items-center justify-between hover:bg-slate-200 dark:hover:bg-slate-700" href=https://polywork.com target=_blank rel=noopener>
<span>Polywork</span>
<span><svg class="h-4 w-4" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 7H6A2 2 0 004 9v9a2 2 0 002 2h9a2 2 0 002-2v-5"/><line x1="10" y1="14" x2="20" y2="4"/><polyline points="15 4 20 4 20 9"/></svg></span>
</a>
</li>
</ul>
<div class=flex-1></div>
<ul class="list-none flex flex-wrap justify-center gap-1 pt-2 border-t border-slate-200 dark:border-slate-600">
<li>
<a class="px-2 py-1.5 rounded-md text-sm block text-slate-800 dark:text-slate-50 hover:bg-slate-200 dark:hover:bg-slate-700" href=https://twitter.com target=_blank rel="noopener noreferrer">
<span class=sr-only>Twitter</span>
<span><svg class="h-4 w-4" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></span>
</a>
</li>
<li>
<a class="px-2 py-1.5 rounded-md text-sm block text-slate-800 dark:text-slate-50 hover:bg-slate-200 dark:hover:bg-slate-700" href=https://github.com target=_blank rel="noopener noreferrer">
<span class=sr-only>GitHub</span>
<span><svg class="h-4 w-4" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></span>
</a>
</li>
<li>
<a class="px-2 py-1.5 rounded-md text-sm block text-slate-800 dark:text-slate-50 hover:bg-slate-200 dark:hover:bg-slate-700" href=https://linkedin.com target=_blank rel="noopener noreferrer">
<span class=sr-only>LinkedIn</span>
<span><svg class="h-4 w-4" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg></span>
</a>
</li>
<li>
<a class="px-2 py-1.5 rounded-md text-sm block text-slate-800 dark:text-slate-50 hover:bg-slate-200 dark:hover:bg-slate-700" href=https://instagram.com target=_blank rel="noopener noreferrer">
<span class=sr-only>Instagram</span>
<span><svg class="h-4 w-4" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="2" y="2" width="20" height="20" rx="5" ry="5"/><path d="M16 11.37A4 4 0 1112.63 8 4 4 0 0116 11.37z"/><line x1="17.5" y1="6.5" x2="17.51" y2="6.5"/></svg></span>
</a>
</li>
<li>
<a class="px-2 py-1.5 rounded-md text-sm block text-slate-800 dark:text-slate-50 hover:bg-slate-200 dark:hover:bg-slate-700" href=https://dribbble.com target=_blank rel="noopener noreferrer">
<span class=sr-only>Dribbble</span>
<span><svg class="h-4 w-4" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><path d="M8.56 2.75c4.37 6.03 6.02 9.42 8.03 17.72m2.54-15.38c-3.72 4.35-8.94 5.66-16.88 5.85m19.5 1.9c-3.5-.93-6.63-.82-8.94.0-2.58.92-5.01 2.86-7.44 6.32"/></svg></span>
</a>
</li>
<li>
<a class="px-2 py-1.5 rounded-md text-sm block text-slate-800 dark:text-slate-50 hover:bg-slate-200 dark:hover:bg-slate-700" href=https://codepen.io target=_blank rel="noopener noreferrer">
<span class=sr-only>Codepen</span>
<span><svg class="h-4 w-4" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polygon points="12 2 22 8.5 22 15.5 12 22 2 15.5 2 8.5 12 2"/><line x1="12" y1="22" x2="12" y2="15.5"/><polyline points="22 8.5 12 15.5 2 8.5"/><polyline points="2 15.5 12 8.5 22 15.5"/><line x1="12" y1="2" x2="12" y2="8.5"/></svg></span>
</a>
</li>
<li>
<a class="px-2 py-1.5 rounded-md text-sm block text-slate-800 dark:text-slate-50 hover:bg-slate-200 dark:hover:bg-slate-700" href=https://twitch.com target=_blank rel="noopener noreferrer">
<span class=sr-only>Twitch</span>
<span><svg class="h-4 w-4" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 2H3v16h5v4l4-4h5l4-4V2zM11 11V7m5 4V7"/></svg></span>
</a>
</li>
<li>
<a class="px-2 py-1.5 rounded-md text-sm block text-slate-800 dark:text-slate-50 hover:bg-slate-200 dark:hover:bg-slate-700" href=mailto:user@example.org target=_blank rel="noopener noreferrer">
<span class=sr-only>Email</span>
<span><svg class="h-4 w-4" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="5" width="18" height="14" rx="2"/><polyline points="3 7 12 13 21 7"/></svg></span>
</a>
</li>
<li>
<a class="px-2 py-1.5 rounded-md text-sm block text-slate-800 dark:text-slate-50 hover:bg-slate-200 dark:hover:bg-slate-700" href=/articles/index.xml target=_blank rel="noopener noreferrer">
<span class=sr-only>RSS</span>
<span><svg class="h-4 w-4" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="5" cy="19" r="1"/><path d="M4 4a16 16 0 0116 16"/><path d="M4 11a9 9 0 019 9"/></svg></span>
</a>
</li>
</ul>
</aside>
<div class="fixed bg-slate-700 bg-opacity-5 transition duration-200 ease-in-out inset-0 z-10 pointer-events-auto md:hidden left-0 top-0 w-full h-full hidden menu-overlay">
</div>
<button aria-label="Toggle Sidebar" class="md:hidden absolute top-3 left-3 z-10 menu-trigger p-1 rounded text-slate-800 dark:text-slate-50 hover:bg-slate-100"><svg class="h-6 w-6" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="4" y1="6" x2="20" y2="6"/><line x1="4" y1="12" x2="20" y2="12"/><line x1="4" y1="18" x2="16" y2="18"/></svg></button>
<div class=flex-1>
<script type=text/javascript async src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['[[',']]']],processEscapes:!0,processEnvironments:!0,skipTags:['script','noscript','style','textarea','pre'],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var b=MathJax.Hub.getAllJax(),a;for(a=0;a<b.length;a+=1)b[a].SourceElement().parentNode.className+=' has-jax'})</script>
<style>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit;color:#515151}</style>
<div class="overflow-y-auto h-screen max-w-full">
<article class="left-3 px-6 py-20 max-w-full mx-10 prose lg:prose-lg h-fit dark:prose-invert prose-img:mx-auto">
<h1 class=!mb-2>DynamicViT:Efficient Vision Transformers with Dynamic Token Sparsification</h1>
<blockquote>
<p>First update: 2022.10.19</p>
</blockquote>
<p>I just write the blog the same time I read it. So I will make it casual and may rewrite some content later.</p>
<p>The authors proposed in the abstract: we observe the final prediction in vision transformers is only based on a subset of most informative tokens, which is sufficient for accurate image recognition.</p>
<ul>
<li>HOW can we come to this conclusion?</li>
</ul>
<p>Visualization:</p>
<p><img src=/images/MS/DynamicVit1.png alt="Attention Visualization"></p>
<h4 id=about-this-visualization-method>About this visualization method:</h4>
<p>Paper related: <a href=https://arxiv.org/pdf/2012.09838 target=_blank rel=noopener>Tranformer interpretability beyond attention visualization</a></p>
<p>Quick Summarization:</p>
<blockquote>
<p>In order to visualize the parts of the image that led to a certain classification, existing methods either rely on the obtained attention maps or employ heuristic propagation along the attention graph.</p>
</blockquote>
<blockquote>
<p>The method assigns local relevance based on the Deep Taylor Decomposition principle and then propagates these relevancy scores through the layers. (A new way to propagate the relevance to better fit the charateristics of the structure of the network)</p>
</blockquote>
<p>And we can also prove this conclusion with the final result.</p>
<h4 id=architecture>Architecture</h4>
<p>$\hat{D}$ Is the mask vector.</p>
<p>$$
\hat{D} \in \lbrace 0, 1 \rbrace^N, x \in R^{N \times C}
$$</p>
<p>$$
z^{local} = MLP(x) \in R^{N \times C^{'}}
$$</p>
<p>$$
z^{global} = Agg(MLP(x), \hat{D}) \in R^{C^{'}}
$$</p>
<p>Where Agg is an aggregation function like average pooling.</p>
<p>Then this model aggregate Zlocal and Zglobal to get Z and then project it(using MLP) to N $\times$ 2 and then use softmax to get a probability matrix to sample the final D.</p>
<p>And it uses the Hadamard product to update $\hat{D}$.</p>
<blockquote>
<p>The Hadamard product can ensure that a token, once dropped, will never be used later.</p>
</blockquote>
<h3 id=dive-deeper>Dive deeper:</h3>
<ul>
<li>About Zlocal and Zglobal:</li>
</ul>
<p>Related code</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#ff79c6>class</span> <span style=color:#50fa7b>PredictorLG</span>(nn<span style=color:#ff79c6>.</span>Module):
    <span style=color:#f1fa8c>&#34;&#34;&#34; Image to Patch Embedding
</span><span style=color:#f1fa8c>    &#34;&#34;&#34;</span>
    <span style=color:#ff79c6>def</span> __init__(self, embed_dim<span style=color:#ff79c6>=</span><span style=color:#bd93f9>384</span>):
        <span style=color:#8be9fd;font-style:italic>super</span>()<span style=color:#ff79c6>.</span>__init__()
        self<span style=color:#ff79c6>.</span>in_conv <span style=color:#ff79c6>=</span> nn<span style=color:#ff79c6>.</span>Sequential(
            nn<span style=color:#ff79c6>.</span>LayerNorm(embed_dim),
            nn<span style=color:#ff79c6>.</span>Linear(embed_dim, embed_dim),
            nn<span style=color:#ff79c6>.</span>GELU()
        )

        self<span style=color:#ff79c6>.</span>out_conv <span style=color:#ff79c6>=</span> nn<span style=color:#ff79c6>.</span>Sequential(
            nn<span style=color:#ff79c6>.</span>Linear(embed_dim, embed_dim <span style=color:#ff79c6>//</span> <span style=color:#bd93f9>2</span>),
            nn<span style=color:#ff79c6>.</span>GELU(),
            nn<span style=color:#ff79c6>.</span>Linear(embed_dim <span style=color:#ff79c6>//</span> <span style=color:#bd93f9>2</span>, embed_dim <span style=color:#ff79c6>//</span> <span style=color:#bd93f9>4</span>),
            nn<span style=color:#ff79c6>.</span>GELU(),
            nn<span style=color:#ff79c6>.</span>Linear(embed_dim <span style=color:#ff79c6>//</span> <span style=color:#bd93f9>4</span>, <span style=color:#bd93f9>2</span>),
            nn<span style=color:#ff79c6>.</span>LogSoftmax(dim<span style=color:#ff79c6>=-</span><span style=color:#bd93f9>1</span>)
        )

    <span style=color:#ff79c6>def</span> <span style=color:#50fa7b>forward</span>(self, x, policy):
        x <span style=color:#ff79c6>=</span> self<span style=color:#ff79c6>.</span>in_conv(x)
        B, N, C <span style=color:#ff79c6>=</span> x<span style=color:#ff79c6>.</span>size()
        local_x <span style=color:#ff79c6>=</span> x[:,:, :C<span style=color:#ff79c6>//</span><span style=color:#bd93f9>2</span>]
        global_x <span style=color:#ff79c6>=</span> (x[:,:, C<span style=color:#ff79c6>//</span><span style=color:#bd93f9>2</span>:] <span style=color:#ff79c6>*</span> policy)<span style=color:#ff79c6>.</span>sum(dim<span style=color:#ff79c6>=</span><span style=color:#bd93f9>1</span>, keepdim<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>) <span style=color:#ff79c6>/</span> torch<span style=color:#ff79c6>.</span>sum(policy, dim<span style=color:#ff79c6>=</span><span style=color:#bd93f9>1</span>, keepdim<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>)
        x <span style=color:#ff79c6>=</span> torch<span style=color:#ff79c6>.</span>cat([local_x, global_x<span style=color:#ff79c6>.</span>expand(B, N, C<span style=color:#ff79c6>//</span><span style=color:#bd93f9>2</span>)], dim<span style=color:#ff79c6>=-</span><span style=color:#bd93f9>1</span>)
        <span style=color:#ff79c6>return</span> self<span style=color:#ff79c6>.</span>out_conv(x)
</code></pre></div><p>I have few experience of training networks and I have the following questions:</p>
<ul>
<li>Why we need to do layernorm before fc-gelu-layer (Or a more basic question: where should we do layernorm)?</li>
</ul>
<p>(Not quite relevant to understanding this paper, will be put in a separate post)</p>
<ul>
<li>Why we need to do in_conv operations as the x we get is already the extracted feature ?</li>
</ul>
<p>My opinion: Intuitively the mlp can improve the expression ability of the tokens. (Basically the MLP layer can just choose to do nothing with the tokens got)</p>
<ul>
<li>Why we need to cut x into localx and globalx and then use policy to get aggregated globalx ?</li>
</ul>
<p>My opinion: We need to make the final Z to have information about both the original feature and the masked feature or just the mask. But the cutting strategy is a little bit strange. It can be explained with its reduced computational complexity but it still challenges common sense. So I believe further experimental results are required.</p>
<ul>
<li>About training strategy and loss design</li>
</ul>
<blockquote>
<p>Not that important, neglected here. (May be complemented when detailed implementation of this paper is required).</p>
</blockquote>
</article>
</div>
</div>
<script type=text/javascript src=/main.js defer></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-PROPERTY_ID','auto'),ga('send','pageview'))</script>
</body>
</html>